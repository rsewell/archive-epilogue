/*
 *  Warning: Do not edit this file.
 *  Auto-generated by 'beam_makeops'.
 */

{
  Eterm nif_bif_result;
  Eterm bif_nif_arity;
  BifFunction vbf;
  ErlHeapFragment *live_hf_end;
  ErtsCodeMFA *codemfa;
  OpCase(apply_bif):
  {
    /*
    * At this point, I points to the code[0] in the export entry for
    * the BIF:
    *
    * code[-3]: Module
    * code[-2]: Function
    * code[-1]: Arity
    * code[0]: &&apply_bif
    * code[1]: Function pointer to BIF function
    */

    if (!((FCALLS - 1) > 0 || (FCALLS - 1) > neg_o_reds)) {
      /* If we have run out of reductions, we do a context
      switch before calling the bif */
      goto context_switch;
    }

    codemfa = erts_code_to_codemfa(I);

    ERTS_MSACC_SET_BIF_STATE_CACHED_X(codemfa->module, (BifFunction)Arg(0));


    /* In case we apply process_info/1,2 or load_nif/1 */
    c_p->current = codemfa;
    c_p->i = I;
    ASSERT(VALID_INSTR(*c_p->i));;     /* In case we apply check_process_code/2. */
    c_p->arity = 0;       /* To allow garbage collection on ourselves
    * (check_process_code/2).
    */
    DTRACE_BIF_ENTRY(c_p, codemfa);

    SWAPOUT;
    ERTS_DBG_CHK_REDS(c_p, FCALLS - 1);
    c_p->fcalls = FCALLS - 1;
    vbf = (BifFunction) Arg(0);
    PROCESS_MAIN_CHK_LOCKS(c_p);
    bif_nif_arity = codemfa->arity;
    ASSERT(bif_nif_arity <= 4);
    ERTS_UNREQ_PROC_MAIN_LOCK(c_p);
    ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
    {
      ErtsBifFunc bf = vbf;
      ASSERT(!ERTS_PROC_IS_EXITING(c_p));
      live_hf_end = c_p->mbuf;
      ERTS_CHK_MBUF_SZ(c_p);
      nif_bif_result = (*bf)(c_p, reg, I);
      ERTS_CHK_MBUF_SZ(c_p);
      ASSERT(!ERTS_PROC_IS_EXITING(c_p) ||
      is_non_value(nif_bif_result));
      ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
      PROCESS_MAIN_CHK_LOCKS(c_p);
    }
    /* We have to update the cache if we are enabled in order
    to make sure no book keeping is done after we disabled
    msacc. We don't always do this as it is quite expensive. */
    if (ERTS_MSACC_IS_ENABLED_CACHED_X())
    ERTS_MSACC_UPDATE_CACHE_X();
    ERTS_MSACC_SET_STATE_CACHED_M_X(ERTS_MSACC_STATE_EMULATOR);
    DTRACE_BIF_RETURN(c_p, codemfa);
  }
  goto nif_bif__epilogue;

  OpCase(call_nif):
  {
    /*
    * call_nif is always first instruction in function:
    *
    * I[-3]: Module
    * I[-2]: Function
    * I[-1]: Arity
    * I[0]: &&call_nif
    * I[1]: Function pointer to NIF function
    * I[2]: Pointer to erl_module_nif
    * I[3]: Function pointer to dirty NIF
    *
    * This layout is determined by the NifExport struct
    */

    ERTS_MSACC_SET_STATE_CACHED_M_X(ERTS_MSACC_STATE_NIF);

    codemfa = erts_code_to_codemfa(I);

    c_p->current = codemfa; /* current and vbf set to please handle_error */

    DTRACE_NIF_ENTRY(c_p, codemfa);

    HEAVY_SWAPOUT;

    PROCESS_MAIN_CHK_LOCKS(c_p);
    bif_nif_arity = codemfa->arity;
    ERTS_UNREQ_PROC_MAIN_LOCK(c_p);

    ASSERT(!ERTS_PROC_IS_EXITING(c_p));
    {
      typedef Eterm NifF(struct enif_environment_t*, int argc, Eterm argv[]);
      NifF* fp = vbf = (NifF*) I[1];
      struct enif_environment_t env;
      ASSERT(c_p->scheduler_data);
      live_hf_end = c_p->mbuf;
      ERTS_CHK_MBUF_SZ(c_p);
      erts_pre_nif(&env, c_p, (struct erl_module_nif*)I[2], NULL);

      ASSERT((c_p->scheduler_data)->current_nif == NULL);
      (c_p->scheduler_data)->current_nif = &env;

      nif_bif_result = (*fp)(&env, bif_nif_arity, reg);
      if (env.exception_thrown)
      nif_bif_result = THE_NON_VALUE;

      ASSERT((c_p->scheduler_data)->current_nif == &env);
      (c_p->scheduler_data)->current_nif = NULL;

      erts_post_nif(&env);
      ERTS_CHK_MBUF_SZ(c_p);

      PROCESS_MAIN_CHK_LOCKS(c_p);
      ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
      ERTS_MSACC_SET_STATE_CACHED_M_X(ERTS_MSACC_STATE_EMULATOR);
      ASSERT(!env.exiting);
      ASSERT(!ERTS_PROC_IS_EXITING(c_p));
    }

    DTRACE_NIF_RETURN(c_p, codemfa);
  }
  goto nif_bif__epilogue;

  nif_bif__epilogue:
  {
    BeamInstr next_pf = BeamCodeAddr(I[1]);
    ERTS_REQ_PROC_MAIN_LOCK(c_p);
    ERTS_HOLE_CHECK(c_p);
    if (ERTS_IS_GC_DESIRED(c_p)) {
      nif_bif_result = erts_gc_after_bif_call_lhf(c_p, live_hf_end,
      nif_bif_result,
      reg, bif_nif_arity);
    }
    SWAPIN;  /* There might have been a garbage collection. */
    FCALLS = c_p->fcalls;
    ERTS_DBG_CHK_REDS(c_p, FCALLS);
    if (ERTS_LIKELY(is_value(nif_bif_result))) {
      r(0) = nif_bif_result;
      CHECK_TERM(r(0));
      SET_I(c_p->cp);
      c_p->cp = 0;
      Goto(*I);
    } else if (c_p->freason == TRAP) {
      SET_I(c_p->i);
      if (c_p->flags & F_HIBERNATE_SCHED) {
        c_p->flags &= ~F_HIBERNATE_SCHED;
        goto do_schedule;
      }
      Dispatch();
    }
    I = handle_error(c_p, c_p->cp, reg, c_p->current);
    goto post_error_handling;
    I += 1;
    ASSERT(VALID_INSTR(next_pf));
    GotoPF(next_pf);
  }

}

OpCase(badarg_j):
{
  c_p->freason = BADARG;

  /*
  * In a correctly working program, we expect failures in
  * guards to be more likely than failures in bodies.
  */

  if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
    ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
    I += jb(BeamExtraData(I[0])) + 0;;
    Goto(*I);;
  }
  goto find_func_info;;;

}

OpCase(badmatch_x):
{
  c_p->fvalue = xb(BeamExtraData(I[0]));
  c_p->freason = BADMATCH;
  goto find_func_info;

}

{
  Eterm context;
  ErlBinMatchBuffer* mb;
  Uint size;
  Uint offs;
  OpCase(bs_context_to_binary_x):
  {
    context = xb(BeamExtraData(I[0]));
    if (is_boxed(context) &&
    header_is_bin_matchstate(*boxed_val(context))) {
      ErlBinMatchState* ms;
      ms = (ErlBinMatchState *) boxed_val(context);
      mb = &ms->mb;
      offs = ms->save_offset[0];
      size = mb->size - offs;
    } else {
      SET_I((BeamInstr *) I+1);
      Goto(*I);;
    }
  }
  goto ctx_to_bin__execute;

  ctx_to_bin__execute:
  {
    BeamInstr next_pf = BeamCodeAddr(I[1]);
    Uint hole_size;
    Uint orig = mb->orig;
    ErlSubBin* sb = (ErlSubBin *) boxed_val(context);
    /* Since we're going to overwrite the match state with the result, an
    * ErlBinMatchState must be at least as large as an ErlSubBin. */
    ERTS_CT_ASSERT(sizeof(ErlSubBin) <= sizeof(ErlBinMatchState));
    hole_size = 1 + header_arity(sb->thing_word) - ERL_SUB_BIN_SIZE;
    sb->thing_word = HEADER_SUB_BIN;
    sb->size = BYTE_OFFSET(size);
    sb->bitsize = BIT_OFFSET(size);
    sb->offs = BYTE_OFFSET(offs);
    sb->bitoffs = BIT_OFFSET(offs);
    sb->is_writable = 0;
    sb->orig = orig;
    if (hole_size) {
      sb[1].thing_word = make_pos_bignum_header(hole_size-1);
    }
    I += 1;
    ASSERT(VALID_INSTR(next_pf));
    GotoPF(next_pf);
  }

}

OpCase(case_end_x):
{
  c_p->fvalue = xb(BeamExtraData(I[0]));
  c_p->freason = EXC_CASE_CLAUSE;
  goto find_func_info;

}

OpCase(cold_is_function2_fxx):
{
  Eterm tmp_packed2 = I[1];
  if (erl_is_function(c_p, xb(tmp_packed2&BEAM_LOOSE_MASK), xb((tmp_packed2>>BEAM_LOOSE_SHIFT))) != am_true ) {
    ASSERT(VALID_INSTR(*(I + (fb(BeamExtraData(I[0]))) + 0)));
    I += fb(BeamExtraData(I[0])) + 0;;
    Goto(*I);;
  }
  I += 2;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(ensure_map_x):
{
  if (is_not_map(xb(BeamExtraData(I[0])))) {
    c_p->freason = BADMAP;
    c_p->fvalue = xb(BeamExtraData(I[0]));
    goto find_func_info;;
  }
  I += 1;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(hipe_call_count):
{
  /*
  * I[-5]: &&lb_i_func_info_IaaI
  * I[-4]: pointer to struct hipe_call_count (inserted by HiPE)
  * I[-3]: Module (tagged atom)
  * I[-2]: Function (tagged atom)
  * I[-1]: Arity (untagged integer)
  * I[ 0]: &&lb_hipe_call_count
  * ... remainder of original BEAM code
  */
  ErtsCodeInfo *ci = erts_code_to_codeinfo(I);
  struct hipe_call_count *hcc = ci->u.hcc;
  ASSERT(IsOpCode(ci->op, i_func_info_IaaI));
  ASSERT(hcc != NULL);
  ASSERT(VALID_INSTR(hcc->opcode));
  ++(hcc->count);
  Goto(hcc->opcode);

}

OpCase(i_bs_restore2_xt):
{
  Eterm tmp_packed1 = BeamExtraData(I[0]);
  BeamInstr next_pf = BeamCodeAddr(I[1]);
  ErlBinMatchState* _ms = (ErlBinMatchState*) boxed_val((Eterm) xb(tmp_packed1&BEAM_TIGHT_MASK));
  ASSERT(HEADER_NUM_SLOTS(_ms->thing_word) > tb((tmp_packed1>>BEAM_TIGHT_SHIFT)));
  _ms->mb.offset = _ms->save_offset[tb((tmp_packed1>>BEAM_TIGHT_SHIFT))];
  I += 1;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(i_bs_save2_xt):
{
  Eterm tmp_packed1 = BeamExtraData(I[0]);
  BeamInstr next_pf = BeamCodeAddr(I[1]);
  ErlBinMatchState* _ms = (ErlBinMatchState*) boxed_val((Eterm) xb(tmp_packed1&BEAM_TIGHT_MASK));
  ASSERT(HEADER_NUM_SLOTS(_ms->thing_word) > tb((tmp_packed1>>BEAM_TIGHT_SHIFT)));
  _ms->save_offset[tb((tmp_packed1>>BEAM_TIGHT_SHIFT))] = _ms->mb.offset;
  I += 1;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

{
  Eterm context;
  OpCase(i_bs_start_match2_xfttd):
  {
    context = xb(BeamExtraData(I[0]));
  }
  goto bs_start_match__execute;

  OpCase(i_bs_start_match2_yfttd):
  {
    context = yb(BeamExtraData(I[0]));
  }
  goto bs_start_match__execute;

  bs_start_match__execute:
  {
    Eterm tmp_packed1 = I[2];
    Eterm dst = db((tmp_packed1>>(2*BEAM_TIGHT_SHIFT)));
    Eterm* dst_ptr = REG_TARGET_PTR(dst);
    Uint slots;
    Uint live;
    Eterm header;
    if (!is_boxed(context)) {
      ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
      I += I[1] + 0;;
      Goto(*I);;
    }
    header = *boxed_val(context);

    /* Reserve a slot for the start position. */
    slots = tb((tmp_packed1>>BEAM_TIGHT_SHIFT)&BEAM_TIGHT_MASK) + 1;
    live = tb(tmp_packed1&BEAM_TIGHT_MASK);

    if (header_is_bin_matchstate(header)) {
      ErlBinMatchState* ms = (ErlBinMatchState *) boxed_val(context);
      Uint actual_slots = HEADER_NUM_SLOTS(header);

      /* We're not compatible with contexts created by bs_start_match3. */
      ASSERT(actual_slots >= 1);

      ms->save_offset[0] = ms->mb.offset;
      if (ERTS_UNLIKELY(actual_slots < slots)) {
        ErlBinMatchState* expanded;
        Uint live = tb(tmp_packed1&BEAM_TIGHT_MASK);
        Uint wordsneeded = ERL_BIN_MATCHSTATE_SIZE(slots);
        do {
          Uint need = wordsneeded;
          if (ERTS_UNLIKELY(E - HTOP < need)) {
            do {
              //
              // Since a garbage collection is expensive anyway, we can afford
              // to save the instruction counter so that the correct function will
              // be pointed in the crash dump if the garbage collection fails
              // because of insufficient memory.
              //
              SWAPOUT;
              c_p->i = I;
            } while (0);
            reg[live] = context;
            PROCESS_MAIN_CHK_LOCKS(c_p);
            FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, live+1, FCALLS);
            ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
            PROCESS_MAIN_CHK_LOCKS(c_p);
            context = reg[live];
            SWAPIN;
          }
          HEAP_SPACE_VERIFIED(wordsneeded);
        } while (0);
        ms = (ErlBinMatchState *) boxed_val(context);
        expanded = (ErlBinMatchState *) HTOP;
        *expanded = *ms;
        *HTOP = HEADER_BIN_MATCHSTATE(slots);
        HTOP += wordsneeded;
        HEAP_SPACE_VERIFIED(0);
        context = make_matchstate(expanded);
        dst_ptr = REG_TARGET_PTR(dst);
      }
      *dst_ptr = context;
    } else if (is_binary_header(header)) {
      Eterm result;
      Uint wordsneeded = ERL_BIN_MATCHSTATE_SIZE(slots);
      do {
        Uint need = wordsneeded;
        if (ERTS_UNLIKELY(E - HTOP < need)) {
          do {
            //
            // Since a garbage collection is expensive anyway, we can afford
            // to save the instruction counter so that the correct function will
            // be pointed in the crash dump if the garbage collection fails
            // because of insufficient memory.
            //
            SWAPOUT;
            c_p->i = I;
          } while (0);
          reg[live] = context;
          PROCESS_MAIN_CHK_LOCKS(c_p);
          FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, live+1, FCALLS);
          ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
          PROCESS_MAIN_CHK_LOCKS(c_p);
          context = reg[live];
          SWAPIN;
        }
        HEAP_SPACE_VERIFIED(wordsneeded);
      } while (0);
      HEAP_TOP(c_p) = HTOP;
#ifdef DEBUG
      c_p->stop = E;	/* Needed for checking in HeapOnlyAlloc(). */
#endif
      result = erts_bs_start_match_2(c_p, context, slots);
      HTOP = HEAP_TOP(c_p);
      HEAP_SPACE_VERIFIED(0);

      dst_ptr = REG_TARGET_PTR(dst);
      *dst_ptr = result;
    } else {
      ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
      I += I[1] + 0;;
      Goto(*I);;
    }
    I += 3;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }

}

OpCase(i_debug_breakpoint):
{
  HEAVY_SWAPOUT;
  I = call_error_handler(c_p, erts_code_to_codemfa(I), reg, am_breakpoint);
  HEAVY_SWAPIN;
  if (I) {
    Goto(*I);
  }
  goto handle_error;

}

OpCase(i_generic_breakpoint):
{
  BeamInstr real_I;
  HEAVY_SWAPOUT;
  real_I = erts_generic_breakpoint(c_p, erts_code_to_codeinfo(I), reg);
  HEAVY_SWAPIN;
  ASSERT(VALID_INSTR(real_I));
  Goto(real_I);

}

OpCase(i_hibernate):
{
  HEAVY_SWAPOUT;
  if (erts_hibernate(c_p, reg)) {
    FCALLS = c_p->fcalls;
    c_p->flags &= ~F_HIBERNATE_SCHED;
    goto do_schedule;
  } else {
    HEAVY_SWAPIN;
    I = handle_error(c_p, I, reg, &bif_export[BIF_hibernate_3]->info.mfa);
    goto post_error_handling;
  }

}

OpCase(i_make_fun_Wt):
{
  BeamInstr next_pf = BeamCodeAddr(I[2]);
  HEAVY_SWAPOUT;
  x(0) = new_fun(c_p, reg, (ErlFunEntry *) I[1], tb(BeamExtraData(I[0])));
  HEAVY_SWAPIN;
  I += 2;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(i_perf_counter):
{
  BeamInstr next_pf = BeamCodeAddr(I[1]);
  ErtsSysPerfCounter ts;

  ts = erts_sys_perf_counter();
  if (IS_SSMALL(ts)) {
    r(0) = make_small((Sint)ts);
  } else {
    do {
      Uint need = ERTS_SINT64_HEAP_SIZE(ts) + 0;
      if (ERTS_UNLIKELY(E - HTOP < need)) {
        do {
          //
          // Since a garbage collection is expensive anyway, we can afford
          // to save the instruction counter so that the correct function will
          // be pointed in the crash dump if the garbage collection fails
          // because of insufficient memory.
          //
          SWAPOUT;
          c_p->i = I;
        } while (0);
        PROCESS_MAIN_CHK_LOCKS(c_p);
        FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, 0, FCALLS);
        ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
        PROCESS_MAIN_CHK_LOCKS(c_p);
        SWAPIN;
      }
      HEAP_SPACE_VERIFIED(ERTS_SINT64_HEAP_SIZE(ts));
    } while (0);
    r(0) = make_big(HTOP);
#if defined(ARCH_32)
    if (ts >= (((Uint64) 1) << 32)) {
      *HTOP = make_pos_bignum_header(2);
      BIG_DIGIT(HTOP, 0) = (Uint) (ts & ((Uint) 0xffffffff));
      BIG_DIGIT(HTOP, 1) = (Uint) ((ts >> 32) & ((Uint) 0xffffffff));
      HTOP += 3;
    }
    else
#endif
    {
      *HTOP = make_pos_bignum_header(1);
      BIG_DIGIT(HTOP, 0) = (Uint) ts;
      HTOP += 2;
    }
  }
  I += 1;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(i_raise):
{
  Eterm raise_trace = x(2);
  Eterm raise_value = x(1);
  struct StackTrace *s;

  c_p->fvalue = raise_value;
  c_p->ftrace = raise_trace;
  s = get_trace_from_exc(raise_trace);
  if (s == NULL) {
    c_p->freason = EXC_ERROR;
  } else {
    c_p->freason = PRIMARY_EXCEPTION(s->freason);
  }
  goto find_func_info;

}

OpCase(i_return_time_trace):
{
  BeamInstr *pc = (BeamInstr *) (UWord) E[0];
  SWAPOUT;
  erts_trace_time_return(c_p, erts_code_to_codeinfo(pc));
  SWAPIN;
  c_p->cp = NULL;
  SET_I((BeamInstr *) cp_val(E[1]));
  E += 2;
  Goto(*I);

}

OpCase(i_return_to_trace):
{
  if (IS_TRACED_FL(c_p, F_TRACE_RETURN_TO)) {
    Uint *cpp = (Uint*) E;
    for(;;) {
      ASSERT(is_CP(*cpp));
      if (IsOpCode(*cp_val(*cpp), return_trace)) {
        do
        ++cpp;
        while (is_not_CP(*cpp));
        cpp += 2;
      } else if (IsOpCode(*cp_val(*cpp), i_return_to_trace)) {
        do
        ++cpp;
        while (is_not_CP(*cpp));
      } else {
        break;
      }
    }
    SWAPOUT;		/* Needed for shared heap */
    ERTS_UNREQ_PROC_MAIN_LOCK(c_p);
    erts_trace_return_to(c_p, cp_val(*cpp));
    ERTS_REQ_PROC_MAIN_LOCK(c_p);
    SWAPIN;
  }
  c_p->cp = NULL;
  SET_I((BeamInstr *) cp_val(E[0]));
  E += 1;
  Goto(*I);

}

OpCase(i_wait_error):
{
  c_p->freason = EXC_TIMEOUT_VALUE;
  goto find_func_info;

}

OpCase(i_wait_error_locked):
{
  erts_proc_unlock(c_p, ERTS_PROC_LOCKS_MSG_RECEIVE);
  c_p->freason = EXC_TIMEOUT_VALUE;
  goto find_func_info;

}

OpCase(i_yield):
{
  /* This is safe as long as REDS_IN(c_p) is never stored
  * in c_p->arg_reg[0]. It is currently stored in c_p->def_arg_reg[5].
  */
  c_p->arg_reg[0] = am_true;
  c_p->arity = 1; /* One living register (the 'true' return value) */
  SWAPOUT;
  c_p->i = I+1;
  ASSERT(VALID_INSTR(*c_p->i));;
  c_p->current = NULL;
  goto do_schedule;

}

OpCase(if_end):
{
  c_p->freason = EXC_IF_CLAUSE;
  goto find_func_info;

}

OpCase(is_atom_fy):
{
  if (is_not_atom(yb(I[1]))) {
    ASSERT(VALID_INSTR(*(I + (fb(BeamExtraData(I[0]))) + 0)));
    I += fb(BeamExtraData(I[0])) + 0;;
    Goto(*I);;
  }
  I += 2;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(is_binary_fy):
{
  if (is_not_binary(yb(I[1])) || binary_bitsize(yb(I[1])) != 0) {
    ASSERT(VALID_INSTR(*(I + (fb(BeamExtraData(I[0]))) + 0)));
    I += fb(BeamExtraData(I[0])) + 0;;
    Goto(*I);;
  }
  I += 2;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(is_bitstring_fy):
{
  if (is_not_binary(yb(I[1]))) {
    ASSERT(VALID_INSTR(*(I + (fb(BeamExtraData(I[0]))) + 0)));
    I += fb(BeamExtraData(I[0])) + 0;;
    Goto(*I);;
  }
  I += 2;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(is_boolean_fx):
{
  if ((xb(I[1])) != am_true && (xb(I[1])) != am_false) {
    ASSERT(VALID_INSTR(*(I + (fb(BeamExtraData(I[0]))) + 0)));
    I += fb(BeamExtraData(I[0])) + 0;;
    Goto(*I);;
  }
  I += 2;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(is_boolean_fy):
{
  if ((yb(I[1])) != am_true && (yb(I[1])) != am_false) {
    ASSERT(VALID_INSTR(*(I + (fb(BeamExtraData(I[0]))) + 0)));
    I += fb(BeamExtraData(I[0])) + 0;;
    Goto(*I);;
  }
  I += 2;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(is_float_fy):
{
  if (is_not_float(yb(I[1]))) {
    ASSERT(VALID_INSTR(*(I + (fb(BeamExtraData(I[0]))) + 0)));
    I += fb(BeamExtraData(I[0])) + 0;;
    Goto(*I);;
  }
  I += 2;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(is_ge_fss):
{
  Eterm targ1;
  Eterm targ2;
  GetSource(I[1], targ1);
  GetSource(I[2], targ2);
  {
    CMP_GE_ACTION(targ1, targ2, ASSERT(VALID_INSTR(*(I + (fb(BeamExtraData(I[0]))) + 0)));
    I += fb(BeamExtraData(I[0])) + 0;;
    Goto(*I););
    I += 3;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }
}

OpCase(is_list_fy):
{
  if (is_not_list(yb(I[1])) && is_not_nil(yb(I[1]))) {
    ASSERT(VALID_INSTR(*(I + (fb(BeamExtraData(I[0]))) + 0)));
    I += fb(BeamExtraData(I[0])) + 0;;
    Goto(*I);;
  }
  I += 2;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(is_lt_fss):
{
  Eterm targ1;
  Eterm targ2;
  GetSource(I[1], targ1);
  GetSource(I[2], targ2);
  {
    CMP_LT_ACTION(targ1, targ2, ASSERT(VALID_INSTR(*(I + (fb(BeamExtraData(I[0]))) + 0)));
    I += fb(BeamExtraData(I[0])) + 0;;
    Goto(*I););
    I += 3;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }
}

OpCase(is_number_fx):
{
  if (is_not_integer(xb(I[1])) && is_not_float(xb(I[1]))) {
    ASSERT(VALID_INSTR(*(I + (fb(BeamExtraData(I[0]))) + 0)));
    I += fb(BeamExtraData(I[0])) + 0;;
    Goto(*I);;
  }
  I += 2;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(is_number_fy):
{
  if (is_not_integer(yb(I[1])) && is_not_float(yb(I[1]))) {
    ASSERT(VALID_INSTR(*(I + (fb(BeamExtraData(I[0]))) + 0)));
    I += fb(BeamExtraData(I[0])) + 0;;
    Goto(*I);;
  }
  I += 2;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(is_pid_fy):
{
  if (is_not_pid(yb(I[1]))) {
    ASSERT(VALID_INSTR(*(I + (fb(BeamExtraData(I[0]))) + 0)));
    I += fb(BeamExtraData(I[0])) + 0;;
    Goto(*I);;
  }
  I += 2;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(is_port_fy):
{
  if (is_not_port(yb(I[1]))) {
    ASSERT(VALID_INSTR(*(I + (fb(BeamExtraData(I[0]))) + 0)));
    I += fb(BeamExtraData(I[0])) + 0;;
    Goto(*I);;
  }
  I += 2;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(is_reference_fy):
{
  if (is_not_ref(yb(I[1]))) {
    ASSERT(VALID_INSTR(*(I + (fb(BeamExtraData(I[0]))) + 0)));
    I += fb(BeamExtraData(I[0])) + 0;;
    Goto(*I);;
  }
  I += 2;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(node_y):
{
  BeamInstr next_pf = BeamCodeAddr(I[1]);
  yb(BeamExtraData(I[0])) = erts_this_node->sysname;
  I += 1;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(put_list_ssd):
{
  Eterm targ1;
  Eterm targ2;
  Eterm dst = db(BeamExtraData(I[0]));
  Eterm* dst_ptr = REG_TARGET_PTR(dst);
  BeamInstr next_pf = BeamCodeAddr(I[3]);
  GetSource(I[1], targ1);
  GetSource(I[2], targ2);
  {
    HTOP[0] = targ1;
    HTOP[1] = targ2;
    *dst_ptr = make_list(HTOP);
    HTOP += 2;
    I += 3;
    ASSERT(VALID_INSTR(next_pf));
    GotoPF(next_pf);
  }
}

OpCase(return_trace):
{
  ErtsCodeMFA* mfa = (ErtsCodeMFA *)(E[0]);

  SWAPOUT;		/* Needed for shared heap */
  ERTS_UNREQ_PROC_MAIN_LOCK(c_p);
  erts_trace_return(c_p, mfa, r(0), ERTS_TRACER_FROM_ETERM(E+1)/* tracer */);
  ERTS_REQ_PROC_MAIN_LOCK(c_p);
  SWAPIN;
  c_p->cp = NULL;
  SET_I((BeamInstr *) cp_val(E[2]));
  E += 3;
  Goto(*I);

}

OpCase(system_limit_j):
{
  c_p->freason = SYSTEM_LIMIT;

  /*
  * In a correctly working program, we expect failures in
  * guards to be more likely than failures in bodies.
  */

  if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
    ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
    I += jb(BeamExtraData(I[0])) + 0;;
    Goto(*I);;
  }
  goto find_func_info;;;

}

OpCase(trace_jump_W):
{
  SET_I((BeamInstr *) I[1]);
  Goto(*I);
}

OpCase(try_case_end_s):
{
  Eterm targ1;
  GetSource(I[1], targ1);
  {
    c_p->fvalue = targ1;
    c_p->freason = EXC_TRY_CLAUSE;
    goto find_func_info;

  }
}

